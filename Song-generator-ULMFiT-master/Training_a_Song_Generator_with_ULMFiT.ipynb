{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "jekyll": {
      "keywords": "fastai",
      "summary": "Application to NLP, including ULMFiT fine-tuning",
      "title": "text"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Training a Song Generator with ULMFiT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aabfc9vJ-kvk",
        "colab_type": "code",
        "outputId": "4fa79d1b-639e-4962-a1dc-c30a97a68752",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1hd4HJ7_CNp",
        "colab_type": "code",
        "outputId": "c8b81a84-65e8-4d14-80a1-04de1682067b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "from base_model1 import *"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7YnEhC6_CIw",
        "colab_type": "code",
        "outputId": "74f4645c-be2f-4b15-e6f6-1aae942730ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        }
      },
      "source": [
        "x = Base_Model(data_size=900, cycles=80)\n",
        "x.run()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Language model saved and vocab dumpped\n",
            "Run one epoch with lower layers\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>6.259577</td>\n",
              "      <td>#na#</td>\n",
              "      <td>00:28</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Run for many epochs with all layers unfrozen\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='9' class='' max='80', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      11.25% [9/80 05:13<41:10]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>5.920238</td>\n",
              "      <td>#na#</td>\n",
              "      <td>00:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>5.814515</td>\n",
              "      <td>#na#</td>\n",
              "      <td>00:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>5.734444</td>\n",
              "      <td>#na#</td>\n",
              "      <td>00:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>5.659799</td>\n",
              "      <td>#na#</td>\n",
              "      <td>00:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>5.551208</td>\n",
              "      <td>#na#</td>\n",
              "      <td>00:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>5.390185</td>\n",
              "      <td>#na#</td>\n",
              "      <td>00:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>5.175111</td>\n",
              "      <td>#na#</td>\n",
              "      <td>00:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>4.989233</td>\n",
              "      <td>#na#</td>\n",
              "      <td>00:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>4.833943</td>\n",
              "      <td>#na#</td>\n",
              "      <td>00:34</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='progress-bar-interrupted' max='63', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      Interrupted\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-133-d4bfbb6d15d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBase_Model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m900\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/base_model1.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Run for many epochs with all layers unfrozen\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munfreeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcyc_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcycles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmoms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ft_love'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ft_enc_love'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/train.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(learn, cyc_len, max_lr, moms, div_factor, pct_start, final_div, wd, callbacks, tot_epochs, start_epoch)\u001b[0m\n\u001b[1;32m     21\u001b[0m     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor, pct_start=pct_start,\n\u001b[1;32m     22\u001b[0m                                        final_div=final_div, tot_epochs=tot_epochs, start_epoch=start_epoch))\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcyc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m def fit_fc(learn:Learner, tot_epochs:int=1, lr:float=defaults.lr,  moms:Tuple[float,float]=(0.95,0.85), start_pct:float=0.72,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callback_fns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mskip_bwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mskip_bwd\u001b[0m\u001b[0;34m:\u001b[0m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/callback.py\u001b[0m in \u001b[0;36mon_backward_begin\u001b[0;34m(self, loss)\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_backward_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0;34m\"Handle gradient calculation on `loss`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmoothener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'smooth_loss'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmoothener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmooth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'backward_begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall_mets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSMeRvkyCGu9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai import *\n",
        "from fastai.text import *\n",
        "#from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "#import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfTHPYTaC4fk",
        "colab_type": "code",
        "outputId": "9a1bad42-777d-4a8a-a565-7aa33a66c8e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "train = pd.read_csv('data_love_fam.csv')\n",
        "train = pd.DataFrame(train['Poem'])\n",
        "train.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1496 entries, 0 to 1495\n",
            "Data columns (total 1 columns):\n",
            "Poem    1496 non-null object\n",
            "dtypes: object(1)\n",
            "memory usage: 11.8+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSrQIpSrDaJB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQdOh-RRC4dB",
        "colab_type": "code",
        "outputId": "f0dab950-5e7b-41dc-ae23-65321fd7a386",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#transfer learning from UMLFit\n",
        "nrows, ncols = train.shape\n",
        "train_size = math.floor(nrows * 0.8)\n",
        "data_lm = TextLMDataBunch.from_df('.', train.iloc[:train_size], train.iloc[train_size:], text_cols=['Poem'], min_freq=1)\n",
        "data_lm.save('lm_databunch_sonnet')\n",
        "#pickle.dump(data_lm.vocab.itos, open('vocab_love.pkl', 'wb'))\n",
        "print (\"Language model saved and vocab dumped\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Language model saved and vocab dumpped\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bw7fWjnpC4au",
        "colab_type": "code",
        "outputId": "d927f41c-d815-4a5c-eaea-bc453eca70f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#run the language_model_learner class\n",
        "learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.7)\n",
        "print (\"Run one epoch with lower layers\")\n",
        "learn.fit_one_cycle(cyc_len=1, max_lr=1e-1, moms=(0.8, 0.7))\n",
        "print (\"Run for many epochs with all layers unfrozen\")\n",
        "learn.unfreeze() \n",
        "learn.fit_one_cycle(cyc_len=30, max_lr=1e-1, moms=(0.8, 0.7))\n",
        "learn.save('ft_love')\n",
        "learn.save_encoder('ft_enc_love')\n",
        "#torch.save(learn.model, 'finetuned_love.pth')\n",
        "print (\"Encoder saved and weights dumpped\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Run one epoch with lower layers\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>6.014570</td>\n",
              "      <td>5.323508</td>\n",
              "      <td>0.189392</td>\n",
              "      <td>00:46</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Run for many epochs with all layers unfrozen\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='16' class='' max='30', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      53.33% [16/30 14:11<12:25]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>5.076503</td>\n",
              "      <td>5.013712</td>\n",
              "      <td>0.205400</td>\n",
              "      <td>00:54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>4.894094</td>\n",
              "      <td>5.116149</td>\n",
              "      <td>0.201903</td>\n",
              "      <td>00:54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>4.891754</td>\n",
              "      <td>5.167446</td>\n",
              "      <td>0.202732</td>\n",
              "      <td>00:54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>4.953993</td>\n",
              "      <td>5.343714</td>\n",
              "      <td>0.194632</td>\n",
              "      <td>00:54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>5.086785</td>\n",
              "      <td>5.452847</td>\n",
              "      <td>0.190561</td>\n",
              "      <td>00:54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>6.471387</td>\n",
              "      <td>6.669869</td>\n",
              "      <td>0.067804</td>\n",
              "      <td>00:53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>6.739645</td>\n",
              "      <td>6.626711</td>\n",
              "      <td>0.036777</td>\n",
              "      <td>00:53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>7.311350</td>\n",
              "      <td>7.344732</td>\n",
              "      <td>0.035278</td>\n",
              "      <td>00:53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>11.877212</td>\n",
              "      <td>8.912408</td>\n",
              "      <td>0.058408</td>\n",
              "      <td>00:52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>12.833594</td>\n",
              "      <td>8.765814</td>\n",
              "      <td>0.064658</td>\n",
              "      <td>00:52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>12.400385</td>\n",
              "      <td>8.777577</td>\n",
              "      <td>0.061182</td>\n",
              "      <td>00:52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>10.463640</td>\n",
              "      <td>7.824969</td>\n",
              "      <td>0.037925</td>\n",
              "      <td>00:52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>9.284677</td>\n",
              "      <td>7.241614</td>\n",
              "      <td>0.035672</td>\n",
              "      <td>00:52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>9.357546</td>\n",
              "      <td>7.400538</td>\n",
              "      <td>0.037202</td>\n",
              "      <td>00:52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>8.633714</td>\n",
              "      <td>7.165081</td>\n",
              "      <td>0.037479</td>\n",
              "      <td>00:52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>8.532198</td>\n",
              "      <td>7.405662</td>\n",
              "      <td>0.061862</td>\n",
              "      <td>00:52</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='progress-bar-interrupted' max='85', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      Interrupted\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-143-0075379e5637>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Run for many epochs with all layers unfrozen\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munfreeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcyc_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmoms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ft_love'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ft_enc_love'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/train.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(learn, cyc_len, max_lr, moms, div_factor, pct_start, final_div, wd, callbacks, tot_epochs, start_epoch)\u001b[0m\n\u001b[1;32m     21\u001b[0m     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor, pct_start=pct_start,\n\u001b[1;32m     22\u001b[0m                                        final_div=final_div, tot_epochs=tot_epochs, start_epoch=start_epoch))\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcyc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m def fit_fc(learn:Learner, tot_epochs:int=1, lr:float=defaults.lr,  moms:Tuple[float,float]=(0.95,0.85), start_pct:float=0.72,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callback_fns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mskip_bwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mskip_bwd\u001b[0m\u001b[0;34m:\u001b[0m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \"\"\"\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LovXJPzEC4X8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#test\n",
        "TEXT = \"In the hot blazing sun\"\n",
        "N_WORDS = 200\n",
        "poem = (learn.predict(TEXT, N_WORDS, temperature = 0.7))\n",
        "print (poem)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gFk6br-C4Vo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1EJtKdqC4Si",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_y0IBeTC4Pw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtUeGw2eC4M6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bqb1gPaHC4Jj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xj5iCdClC4Gf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2GfdbheC4Es",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xO8EEv7C4Bj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-5tIU1dC3-B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVlNS2eoCGGe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_XkzXd8CF7S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOCjJf2jCFu7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMBd73mmz0Vt",
        "colab_type": "text"
      },
      "source": [
        "## Training a Song Generator with *ULMFiT*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssfv6Mquz0V6",
        "colab_type": "text"
      },
      "source": [
        "Let's start with a quick end-to-end example of training a model. We'll train a song generator, showing 4 steps:\n",
        "\n",
        "1. Reading and viewing the songdata\n",
        "1. Getting your data ready for modeling\n",
        "1. Fine-tuning a language model\n",
        "\n",
        "More detailed notebook: https://github.com/prrao87/tweet-stance-prediction/blob/master/ulmfit.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbjgrUE7_CEf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScWPhv-Cz0V-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai.text import * "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cjnAv0Cz0WQ",
        "colab_type": "text"
      },
      "source": [
        "Contrary to images in Computer Vision, text can't directly be transformed into numbers to be fed into a model. The first thing we need to do is to preprocess our data so that we change the raw texts to lists of words, or tokens (a step that is called tokenization) then transform these tokens into numbers (a step that is called numericalization). These numbers are then passed to embedding layers that will convert them in arrays of floats before passing them through a model.\n",
        "\n",
        "Steps:\n",
        "\n",
        "1. Get your data preprocessed and ready to use,\n",
        "1. Create a language model with pretrained weights that you can fine-tune to your dataset\n",
        "\n",
        "Now, we will import our song lyrics data from kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ky_ax0ngcaSK",
        "colab_type": "code",
        "outputId": "12318e10-1c1f-41a7-9657-146aeb763020",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        }
      },
      "source": [
        "import json\n",
        "import zipfile\n",
        "import os\n",
        "#import kaggle"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-6945289037f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkaggle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kaggle/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mapi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKaggleApi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mApiClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthenticate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kaggle/api/kaggle_api_extended.py\u001b[0m in \u001b[0;36mauthenticate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    147\u001b[0m                 raise IOError('Could not find {}. Make sure it\\'s located in'\n\u001b[1;32m    148\u001b[0m                               ' {}. Or use the environment method.'.format(\n\u001b[0;32m--> 149\u001b[0;31m                                   self.config_file, self.config_dir))\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;31m# Step 3: load into configuration!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPpbsv8RccyQ",
        "colab_type": "code",
        "outputId": "f7339937-bd60-43d1-e153-5b2b04d50531",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = \"febriy\" # username from the json file \n",
        "os.environ['KAGGLE_KEY'] = \"38eb10cfc0a96aa36bae3e2f6fd1b329\" # key from the json file\n",
        "!kaggle datasets download -d mousehead/songlyrics # api copied from kaggle"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "401 - Unauthorized\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6JEaXlvdBw2",
        "colab_type": "text"
      },
      "source": [
        "Unzipping file:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHYxq87NJU6O",
        "colab_type": "code",
        "outputId": "25277460-a264-4952-8486-da0d82747207",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "!unzip songlyrics.zip -y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unzip:  cannot find or open songlyrics.zip, songlyrics.zip.zip or songlyrics.zip.ZIP.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBnR5iqzDHpA",
        "colab_type": "text"
      },
      "source": [
        "## Open songdata"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqXoKxBMz0Wl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('drive/My Drive/songdata.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moSVnfkzSdFp",
        "colab_type": "code",
        "outputId": "48623857-446c-4b70-93c7-079c8c626b76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>artist</th>\n",
              "      <th>song</th>\n",
              "      <th>link</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ABBA</td>\n",
              "      <td>Ahe's My Kind Of Girl</td>\n",
              "      <td>/a/abba/ahes+my+kind+of+girl_20598417.html</td>\n",
              "      <td>Look at her face, it's a wonderful face  \\nAnd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ABBA</td>\n",
              "      <td>Andante, Andante</td>\n",
              "      <td>/a/abba/andante+andante_20002708.html</td>\n",
              "      <td>Take it easy with me, please  \\nTouch me gentl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ABBA</td>\n",
              "      <td>As Good As New</td>\n",
              "      <td>/a/abba/as+good+as+new_20003033.html</td>\n",
              "      <td>I'll never know why I had to go  \\nWhy I had t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ABBA</td>\n",
              "      <td>Bang</td>\n",
              "      <td>/a/abba/bang_20598415.html</td>\n",
              "      <td>Making somebody happy is a question of give an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ABBA</td>\n",
              "      <td>Bang-A-Boomerang</td>\n",
              "      <td>/a/abba/bang+a+boomerang_20002668.html</td>\n",
              "      <td>Making somebody happy is a question of give an...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  artist  ...                                               text\n",
              "0   ABBA  ...  Look at her face, it's a wonderful face  \\nAnd...\n",
              "1   ABBA  ...  Take it easy with me, please  \\nTouch me gentl...\n",
              "2   ABBA  ...  I'll never know why I had to go  \\nWhy I had t...\n",
              "3   ABBA  ...  Making somebody happy is a question of give an...\n",
              "4   ABBA  ...  Making somebody happy is a question of give an...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJM17F_1TqfT",
        "colab_type": "text"
      },
      "source": [
        "Now, let's get rid of any row with na value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2IdwZidTRR8",
        "colab_type": "code",
        "outputId": "4805e490-a72b-46c9-edc6-b68f67fe59ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df = df.dropna()\n",
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(57650, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNkNSq8xT4OF",
        "colab_type": "text"
      },
      "source": [
        "We only want the text for now:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDxRSzRrUO81",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.drop (columns=[\"artist\",\"song\",\"link\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFQhZVWmjOop",
        "colab_type": "text"
      },
      "source": [
        "Choose only a portion of dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ixo3ENwmjOWw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df[:1000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEbg895_jmhX",
        "colab_type": "code",
        "outputId": "b236fb29-3ccf-4a37-f005-5de7bca67f32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGjt78RTekfE",
        "colab_type": "code",
        "outputId": "449c8fa6-6a4e-4955-f8e0-a331def51f27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Look at her face, it's a wonderful face  \\nAnd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Take it easy with me, please  \\nTouch me gentl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I'll never know why I had to go  \\nWhy I had t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Making somebody happy is a question of give an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Making somebody happy is a question of give an...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0  Look at her face, it's a wonderful face  \\nAnd...\n",
              "1  Take it easy with me, please  \\nTouch me gentl...\n",
              "2  I'll never know why I had to go  \\nWhy I had t...\n",
              "3  Making somebody happy is a question of give an...\n",
              "4  Making somebody happy is a question of give an..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJ54i2TPQLtG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrjS0L7UQLrk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4y8FgMPQLp9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSPMm2ceQLmo",
        "colab_type": "code",
        "outputId": "2bfd584e-c7b8-4d59-d5fc-da7994413ec4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# interject: training using shakedpeare sonnets\n",
        "df = pd.read_csv('sonnets.txt', delimiter=\" /s \", header=None)\n",
        "df.columns = [\"text\"]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dyo9Y7ovQLi2",
        "colab_type": "code",
        "outputId": "4ecee60c-be0e-48bb-cc70-69a5a9158b63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>From fairest creatures we desire increase,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>That thereby beauty's rose might never die,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>But as the riper should by time decease,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>His tender heir might bear his memory:</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>But thou contracted to thine own bright eyes,</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            text\n",
              "0     From fairest creatures we desire increase,\n",
              "1    That thereby beauty's rose might never die,\n",
              "2       But as the riper should by time decease,\n",
              "3         His tender heir might bear his memory:\n",
              "4  But thou contracted to thine own bright eyes,"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neFL3FdJQLfD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZDhKih_ERhr",
        "colab_type": "text"
      },
      "source": [
        "## Train a language model\n",
        "A language model is able to predict next word given a particular input word. For the transfer learning, we start with a pre-trained model that was trained on Wikipedia dataset. \n",
        "\n",
        "Here, we will use our song lyrics to re-train the model, enabling it to hopefully be able to compose songs!\n",
        "\n",
        "### Create [DataBunch](https://medium.com/@tmckenzie.nz/using-the-fastai-data-block-api-b4818e72155b), which is the data-containing object we need to feed the neural network \n",
        "\n",
        "Load dataset in Language Model form"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Av9shrANz0Ww",
        "colab_type": "code",
        "outputId": "ac5d2365-3861-4ea3-cc99-fb34eba2893e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        }
      },
      "source": [
        "nrows, ncols = df.shape\n",
        "train_size = math.floor(nrows * 0.8)\n",
        "data_lm = TextLMDataBunch.from_df('.', df.iloc[:train_size], df.iloc[train_size:], text_cols=['text'])\n",
        "data_lm"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TextLMDataBunch;\n",
              "\n",
              "Train: LabelList (1725 items)\n",
              "x: LMTextList\n",
              "xxbos xxmaj from fairest xxunk we desire increase ,,xxbos xxmaj that thereby beauty 's rose might never die ,,xxbos xxmaj but as the riper should by time decease ,,xxbos xxmaj his tender heir might bear his memory :,xxbos xxmaj but thou contracted to thine own bright eyes ,\n",
              "y: LMLabelList\n",
              ",,,,\n",
              "Path: .;\n",
              "\n",
              "Valid: LabelList (432 items)\n",
              "x: LMTextList\n",
              "xxbos xxmaj as subject to xxmaj time 's love or to xxmaj time 's hate ,,xxbos xxmaj weeds xxunk weeds , or flowers with flowers xxunk .,xxbos xxmaj no , it was xxunk far from xxunk ;,xxbos xxmaj it xxunk not in xxunk xxunk , nor xxunk,xxbos xxmaj under the xxunk of xxunk xxunk ,\n",
              "y: LMLabelList\n",
              ",,,,\n",
              "Path: .;\n",
              "\n",
              "Test: None"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuP8nxWGz0W5",
        "colab_type": "code",
        "outputId": "441e8578-3320-4354-f01a-b23739d92c53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        }
      },
      "source": [
        "data_lm.show_batch()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>idx</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>where abundance lies , xxbos xxmaj thy self thy xxunk , to thy sweet self too cruel : xxbos xxmaj thou that art now the world 's fresh ornament , xxbos xxmaj and only xxunk to the xxunk spring , xxbos xxmaj within thine own bud xxunk thy content , xxbos xxmaj and , tender churl , mak'st waste in xxunk : xxbos xxmaj pity the world , or else</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>whose xxunk womb xxbos xxmaj xxunk the xxunk of thy husbandry ? xxbos xxmaj or who is he so fond will be the tomb xxbos xxmaj of his self - love , to stop posterity ? xxbos xxmaj thou art thy mother 's glass and she in thee xxbos xxmaj calls back the lovely xxmaj april of her prime ; xxbos xxmaj so thou through windows of thine age shalt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>xxmaj to hideous winter , and confounds him there ; xxbos xxmaj sap checked with xxunk , and lusty leaves quite gone , xxbos xxmaj beauty o'er - xxunk and bareness every where : xxbos xxmaj then were not summer 's xxunk left , xxbos a xxunk xxunk xxunk in xxunk of glass , xxbos xxmaj beauty 's effect with beauty were xxunk , xxbos xxmaj nor it , nor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>up heavenly xxunk , xxbos xxmaj resembling strong youth in his xxunk age , xxbos xxmaj yet mortal looks xxunk his beauty still , xxbos xxmaj attending on his golden pilgrimage : xxbos xxmaj but when from xxunk pitch , with weary xxunk , xxbos xxmaj like xxunk age , he xxunk from the day , xxbos xxmaj the eyes , ' fore xxunk , now converted are xxbos xxmaj</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>; xxbos xxmaj the world will be thy widow and still weep xxbos xxmaj that thou no form of thee hast left behind , xxbos xxmaj when every xxunk widow well may keep xxbos xxmaj by children 's eyes , her husband 's shape in mind : xxbos xxmaj look what an xxunk in the world doth spend xxbos xxmaj xxunk but his place , for still the world xxunk</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rqpQql_Vf4b",
        "colab_type": "text"
      },
      "source": [
        "Let's save our databunch for next time:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jP2xDA3Cz0W_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_lm.save('lm_databunch_sonnets')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVSibpvPz0XP",
        "colab_type": "text"
      },
      "source": [
        "Note that you can load the data with different [`DataBunch`](/basic_data.html#DataBunch) parameters (batch size, `bptt`,...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56J1w1CMz0XT",
        "colab_type": "text"
      },
      "source": [
        "### Loading saved data, and creating the language model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yf9V6rlz0XW",
        "colab_type": "text"
      },
      "source": [
        "We can use the `data_lm` object we created earlier to fine-tune a pretrained language model. [fast.ai](http://www.fast.ai/) has an English model with an AWD-LSTM architecture available that we can download. We can create a learner object that will directly create a model, download the pretrained weights and be ready for fine-tuning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLo99R_4qCKn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bs = 192\n",
        "path = Path('.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3IJiKIQqB8u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_lm = load_data(path, 'lm_databunch_sonnets', bs=bs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVYpqjATV1_5",
        "colab_type": "text"
      },
      "source": [
        "We can add this dataset into a learner object with a model loaded with the pretrained weight. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYij0hBSz0Xh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTahKc_I8B1U",
        "colab_type": "text"
      },
      "source": [
        "Extra: we can print the structure of the language model RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_INC4caw8IZA",
        "colab_type": "code",
        "outputId": "d094e9e2-3a5f-4cc1-857d-d7332d4885b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        }
      },
      "source": [
        "list(learn.model.children())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[AWD_LSTM(\n",
              "   (encoder): Embedding(1160, 400, padding_idx=1)\n",
              "   (encoder_dp): EmbeddingDropout(\n",
              "     (emb): Embedding(1160, 400, padding_idx=1)\n",
              "   )\n",
              "   (rnns): ModuleList(\n",
              "     (0): WeightDropout(\n",
              "       (module): LSTM(400, 1152, batch_first=True)\n",
              "     )\n",
              "     (1): WeightDropout(\n",
              "       (module): LSTM(1152, 1152, batch_first=True)\n",
              "     )\n",
              "     (2): WeightDropout(\n",
              "       (module): LSTM(1152, 400, batch_first=True)\n",
              "     )\n",
              "   )\n",
              "   (input_dp): RNNDropout()\n",
              "   (hidden_dps): ModuleList(\n",
              "     (0): RNNDropout()\n",
              "     (1): RNNDropout()\n",
              "     (2): RNNDropout()\n",
              "   )\n",
              " ), LinearDecoder(\n",
              "   (decoder): Linear(in_features=400, out_features=1160, bias=True)\n",
              "   (output_dp): RNNDropout()\n",
              " )]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49lJoSIz8H5J",
        "colab_type": "text"
      },
      "source": [
        "### Find the optimum learning rate\n",
        "\n",
        "What is the learning rate? It is the distance/ steps change of model parameter every epoch. \n",
        "\n",
        "You don't want a learning rate that is too big, because you might miss the best point. You don't wanr a learning rate that is too small, because you'll take too long to train.\n",
        "\n",
        "We will use fastai's learning rate finder. Choose something when the loss is still decreasing. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhUVLhLN8RVI",
        "colab_type": "code",
        "outputId": "f4eebc71-1b36-4443-865f-2c3c6f44d0fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "learn.lr_find(start_lr=1e-3, end_lr=1e2)\n",
        "learn.recorder.plot()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEGCAYAAABvtY4XAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niVAKeBGRCPV/vUWke7ai15EAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynfXe5wU8i6F",
        "colab_type": "text"
      },
      "source": [
        "### Run the language_model_learner class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXWUME8x8ilj",
        "colab_type": "code",
        "outputId": "b6b8a88c-2b83-4e3a-9e79-5c10f2c94c77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "learn.fit_one_cycle(cyc_len=1, max_lr=1e-1, moms=(0.8, 0.7))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>5.982650</td>\n",
              "      <td>5.248903</td>\n",
              "      <td>0.214583</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuKwOLIhz0YC",
        "colab_type": "text"
      },
      "source": [
        "### Unfreeze the entire model\n",
        "To complete the fine-tuning, we can then unfreeze the model and fine-tune it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFsiu7aYXvjK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.unfreeze()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7DNx5cxXxkq",
        "colab_type": "text"
      },
      "source": [
        "Fit for 20 epoch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQBqs0zNz0YJ",
        "colab_type": "code",
        "outputId": "cb2e998b-8a3c-4513-d4e2-d37b65ab2666",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        }
      },
      "source": [
        "learn.fit_one_cycle(cyc_len=20, max_lr=1e-3, moms=(0.8, 0.7))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.157040</td>\n",
              "      <td>3.721456</td>\n",
              "      <td>0.306399</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3.171857</td>\n",
              "      <td>3.721968</td>\n",
              "      <td>0.305283</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>3.159294</td>\n",
              "      <td>3.731735</td>\n",
              "      <td>0.302976</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>3.146991</td>\n",
              "      <td>3.741076</td>\n",
              "      <td>0.308631</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>3.117488</td>\n",
              "      <td>3.781140</td>\n",
              "      <td>0.294494</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>3.079603</td>\n",
              "      <td>3.807837</td>\n",
              "      <td>0.302753</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>3.035048</td>\n",
              "      <td>3.873974</td>\n",
              "      <td>0.290030</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>2.989988</td>\n",
              "      <td>3.876708</td>\n",
              "      <td>0.285119</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>2.947263</td>\n",
              "      <td>3.898700</td>\n",
              "      <td>0.299702</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>2.916405</td>\n",
              "      <td>4.022411</td>\n",
              "      <td>0.273958</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.865552</td>\n",
              "      <td>3.963734</td>\n",
              "      <td>0.291815</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>2.815949</td>\n",
              "      <td>4.075679</td>\n",
              "      <td>0.280804</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>2.757498</td>\n",
              "      <td>4.021336</td>\n",
              "      <td>0.292411</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>2.702330</td>\n",
              "      <td>4.067865</td>\n",
              "      <td>0.283259</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>2.648813</td>\n",
              "      <td>4.106321</td>\n",
              "      <td>0.281771</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>2.599092</td>\n",
              "      <td>4.119514</td>\n",
              "      <td>0.282366</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>2.551982</td>\n",
              "      <td>4.125323</td>\n",
              "      <td>0.285417</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>2.510459</td>\n",
              "      <td>4.124236</td>\n",
              "      <td>0.284152</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>2.470809</td>\n",
              "      <td>4.125702</td>\n",
              "      <td>0.283557</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>2.435982</td>\n",
              "      <td>4.130232</td>\n",
              "      <td>0.283110</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY4PwCOdz0YU",
        "colab_type": "text"
      },
      "source": [
        "To evaluate your language model, you can run the [`Learner.predict`](/basic_train.html#Learner.predict) method and specify the number of words you want it to guess."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Tn33c-YoFEE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT = \"thou art my enemy\"\n",
        "N_WORDS = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOdpb1-BonMJ",
        "colab_type": "code",
        "outputId": "53ba9b7f-9026-412b-e3cc-6c77a7d646d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "poem = learn.predict(TEXT, N_WORDS, temperature = 0.75)\n",
        "print (poem)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "thou art my enemy and errors make turns ? xxbos So fair a fool is love , that thus is my love . xxbos Than those old lovers ' loves , that you do know xxbos Within the knowledge of mine own desert , xxbos To me that you are\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rwtfof7L2j1Y",
        "colab_type": "code",
        "outputId": "ff995a76-de20-4cb4-edab-48659c63526d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "thou art my enemy and the beauties ' faces xxbos And for my sake only love seem false , xxbos And my sweet flower again be sweet , xxbos Having no influence upon thy heart , xxbos And she in thee holds a prize : xxbos That with men\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vy4eoq2Gosa8",
        "colab_type": "text"
      },
      "source": [
        "See the effect of temperature above. A higher temperature value makes the song more 'creative' and less repetitive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnvVbw-ez0Yg",
        "colab_type": "text"
      },
      "source": [
        "The song generated might not make much sense (we have a tiny vocabulary here and didn't train much on it) but note that it respects basic grammar (which comes from the pretrained model).\n",
        "\n",
        "Finally we save the encoder to be able to use it for classification in the next section."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-DHMdXbz0Yi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.save('fine_tuned_20')\n",
        "learn.save_encoder('fine_tuned_enc_20')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwWTwIIvz0Yq",
        "colab_type": "text"
      },
      "source": [
        "What have we done? We have re-trained a language model initially trained on Wikipedia to now be able to produce tweets. \n",
        "\n",
        "We will use this language model to build a classifier next. \n",
        "\n",
        "### Next: Building a classifier\n",
        "Perhaps we can build a classifier that can differentiate between different artists?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aaIrbFpe4Im",
        "colab_type": "text"
      },
      "source": [
        "## Testing to load trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4nObc1oe3HQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vDq-TtGdj5UT",
        "colab": {}
      },
      "source": [
        "bs = 192\n",
        "path = Path('.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "c2tC1prjjz2u",
        "colab": {}
      },
      "source": [
        "data_lm = load_data(path, 'lm_databunch', bs=bs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55aIF4Hze3FS",
        "colab_type": "code",
        "outputId": "fb6f2b9c-41c9-4652-9381-e94fbde29294",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "learntest = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.5)\n",
        "learntest.load_encoder ('fine_tuned_enc_20')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LanguageLearner(data=TextLMDataBunch;\n",
              "\n",
              "Train: LabelList (800 items)\n",
              "x: LMTextList\n",
              "xxbos xxmaj look at her face , it 's a wonderful face \n",
              "  xxmaj and it means something special to me \n",
              "  xxmaj look at the way that she smiles when she sees me \n",
              "  xxmaj how lucky can one fellow be ? \n",
              " \n",
              "  xxmaj she 's just my kind of girl , she makes me feel fine \n",
              "  xxmaj who could ever believe that she could be mine ? \n",
              "  xxmaj she 's just my kind of girl , without her i 'm blue \n",
              "  xxmaj and if she ever leaves me what could i do , what could i do ? \n",
              " \n",
              "  xxmaj and when we go for a walk in the park \n",
              "  xxmaj and she holds me and xxunk my hand \n",
              "  xxmaj we 'll go on walking for hours and talking \n",
              "  xxmaj about all the things that we plan \n",
              " \n",
              "  xxmaj she 's just my kind of girl , she makes me feel fine \n",
              "  xxmaj who could ever believe that she could be mine ? \n",
              "  xxmaj she 's just my kind of girl , without her i 'm blue \n",
              "  xxmaj and if she ever leaves me what could i do , what could i do ? \n",
              " \n",
              " ,xxbos xxmaj take it easy with me , please \n",
              "  xxmaj touch me gently like a summer evening breeze \n",
              "  xxmaj take your time , make it slow \n",
              "  xxmaj andante , xxmaj andante \n",
              "  xxmaj just let the feeling grow \n",
              " \n",
              "  xxmaj make your fingers soft and light \n",
              "  xxmaj let your body be the xxunk of the night \n",
              "  xxmaj touch my soul , you know how \n",
              "  xxmaj andante , xxmaj andante \n",
              "  xxmaj go slowly with me now \n",
              " \n",
              "  i 'm your music \n",
              "  ( i am your music and i am your song ) \n",
              "  i 'm your song \n",
              "  ( i am your music and i am your song ) \n",
              "  xxmaj play me time and time again and make me strong \n",
              "  ( xxmaj play me again 'cause you 're making me strong ) \n",
              "  xxmaj make me sing , make me sound \n",
              "  ( xxmaj you make me sing and you make me ) \n",
              "  xxmaj andante , xxmaj andante \n",
              "  xxmaj tread lightly on my ground \n",
              "  xxmaj andante , xxmaj andante \n",
              "  xxmaj oh please do n't let me down \n",
              " \n",
              "  xxmaj there 's a xxunk in your eyes \n",
              "  xxmaj like the feeling of a thousand butterflies \n",
              "  xxmaj please do n't talk , go on , play \n",
              "  xxmaj andante , xxmaj andante \n",
              "  xxmaj and let me float away \n",
              " \n",
              "  i 'm your music \n",
              "  ( i am your music and i am your song ) \n",
              "  i 'm your song \n",
              "  ( i am your music and i am your song ) \n",
              "  xxmaj play me time and time again and make me strong \n",
              "  ( xxmaj play me again 'cause you 're making me strong ) \n",
              "  xxmaj make me sing , make me sound \n",
              "  ( xxmaj you make me sing and you make me ) \n",
              "  xxmaj andante , xxmaj andante \n",
              "  xxmaj tread lightly on my ground \n",
              "  xxmaj andante , xxmaj andante \n",
              "  xxmaj oh please do n't let me down \n",
              " \n",
              "  xxmaj make me sing , make me sound \n",
              "  ( xxmaj you make me sing and you make me ) \n",
              "  xxmaj andante , xxmaj andante \n",
              "  xxmaj tread lightly on my ground \n",
              "  xxmaj andante , xxmaj andante \n",
              "  xxmaj oh please do n't let me down \n",
              "  xxmaj andante , xxmaj andante \n",
              "  xxmaj oh please do n't let me down \n",
              " \n",
              " ,xxbos i 'll never know why i had to go \n",
              "  xxmaj why i had to put up such a lousy rotten show \n",
              "  xxmaj boy , i was tough , packing all my stuff \n",
              "  xxmaj saying i do n't need you anymore , i 've had enough \n",
              "  xxmaj and now , look at me standing here again 'cause i found out that \n",
              "  xxmaj ma xxwrep 15 ma my life is here \n",
              "  xxmaj got ta have you near \n",
              " \n",
              "  xxmaj as good as new , my love for you \n",
              "  xxmaj and keeping it that way is my intention \n",
              "  xxmaj as good as new and growing too \n",
              "  xxmaj yes , i think it 's taking on a new dimension \n",
              "  xxmaj it 's as good as new , my love for you \n",
              "  xxmaj just like it used to be and even better \n",
              "  xxmaj as good as new , thank xxmaj god it 's true \n",
              "  xxmaj darling , we were always meant to stay together \n",
              " \n",
              "  xxmaj feel like a xxunk , never felt so cheap \n",
              "  xxmaj never had a notion that my love could be so deep \n",
              "  xxmaj how could i make such a dumb mistake \n",
              "  xxmaj now i know i 'm not xxunk to another break \n",
              "  xxmaj but please , baby , i beg you to forgive 'cause i found out that \n",
              "  xxmaj ma xxwrep 15 ma my life is here \n",
              "  xxmaj got ta get you near \n",
              " \n",
              "  i thought that our love was at an end but here i am again \n",
              " \n",
              "  xxmaj as good as new , my love for you \n",
              "  xxmaj and keeping it that way is my intention \n",
              "  xxmaj as good as new and growing too \n",
              "  xxmaj yes , i think it 's taking on a new dimension \n",
              "  xxmaj it 's as good as new , my love for you \n",
              "  xxmaj just like it used to be and even better \n",
              "  xxmaj as good as new , thank xxmaj god it 's true \n",
              "  xxmaj darling , we were always meant to stay together \n",
              " \n",
              "  xxmaj yes the love i have for you feels as good as new \n",
              "  xxmaj darling , we were always meant to stay together \n",
              " \n",
              " ,xxbos xxmaj making somebody happy is a question of give and take \n",
              "  xxmaj you can learn how to show it so come on , give yourself a break \n",
              "  xxmaj every smile and every little touch \n",
              "  xxmaj do n't you know that they mean so much \n",
              "  xxmaj sweet sweet kisses so tender \n",
              "  xxmaj always will return to sender \n",
              " \n",
              "  xxmaj like a bang , a boom - a - boomerang \n",
              "  xxmaj dum - be - dum - dum be - dum - be - dum - dum \n",
              "  xxmaj oh bang , a boom - a - boomerang \n",
              "  xxmaj love is a tune you hum - de - hum - hum \n",
              "  xxmaj so give it away , i think you 'll learn \n",
              "  xxmaj you 'll get love in return \n",
              "  xxmaj so bang , a boom - a - boomerang is love \n",
              "  a boom - a - boomerang is love \n",
              " \n",
              "  xxmaj love is always around and you can look for it anywhere \n",
              "  xxmaj when you feel that you 've found it my advice is to take good care \n",
              "  xxmaj never use it as a selfish tool \n",
              "  xxmaj never ever be such a fool \n",
              "  xxmaj every feeling you 're showing \n",
              "  xxmaj is a boomerang you 're throwing \n",
              " \n",
              "  xxmaj yes a bang , a boom - a - boomerang \n",
              "  xxmaj dum - be - dum - dum be - dum - be - dum - dum \n",
              "  xxmaj oh bang , a boom - a - boomerang \n",
              "  xxmaj love is a tune you hum - de - hum - hum \n",
              "  xxmaj so give it away , i think you 'll learn \n",
              "  xxmaj you 'll get love in return \n",
              "  xxmaj so bang , a boom - a - boomerang is love \n",
              " \n",
              "  xxmaj and if you 're warm and tender \n",
              "  i 'll kiss you , return to sender \n",
              "  xxmaj please surrender \n",
              " \n",
              "  xxmaj bang , a boom - a - boomerang \n",
              "  xxmaj dum - be - dum - dum be - dum - be - dum - dum \n",
              "  xxmaj oh bang , a boom - a - boomerang is love \n",
              "  a boom - a - boomerang is love \n",
              " \n",
              " ,xxbos xxmaj making somebody happy is a question of give and take \n",
              "  xxmaj you can learn how to show it so come on , give yourself a break \n",
              "  xxmaj every smile and every little touch \n",
              "  xxmaj do n't you know that they mean so much \n",
              "  xxmaj sweet sweet kisses so tender \n",
              "  xxmaj always will return to sender \n",
              " \n",
              "  xxmaj like a bang , a boom - a - boomerang \n",
              "  xxmaj dumb - be - dumb - dumb be - dumb - be - dumb - dumb \n",
              "  xxmaj oh bang , a boom - a - boomerang \n",
              "  xxmaj love is a tune you hum - de - hum - hum \n",
              "  xxmaj by giving away , i think you 'll learn \n",
              "  xxmaj you 'll get love in return \n",
              "  xxmaj so bang , a boom - a - boomerang is love \n",
              "  a boom - a - boomerang is love \n",
              " \n",
              "  xxmaj love is always around and you can look for it anywhere \n",
              "  xxmaj when you feel that you 've found it my advice is to take good care \n",
              "  xxmaj never use it as a selfish tool \n",
              "  xxmaj never ever be such a fool \n",
              "  xxmaj every feeling you 're showing \n",
              "  xxmaj is a boomerang you 're throwing \n",
              " \n",
              "  xxmaj yes a bang , a boom - a - boomerang \n",
              "  xxmaj dumb - be - dumb - dumb be - dumb - be - dumb - dumb \n",
              "  xxmaj oh bang , a boom - a - boomerang \n",
              "  xxmaj love is a tune you hum - de - hum - hum \n",
              "  xxmaj by giving away , i think you 'll learn \n",
              "  xxmaj you 'll get love in return \n",
              "  xxmaj so bang , a boom - a - boomerang is love \n",
              " \n",
              "  xxmaj and if you 're warm and tender \n",
              "  i 'll kiss you , return to sender \n",
              "  xxmaj please surrender \n",
              " \n",
              "  xxmaj bang , a boom - a - boomerang \n",
              "  xxmaj dumb - be - dumb - dumb be - dumb - be - dumb - dumb \n",
              "  xxmaj oh bang , a boom - a - boomerang is love \n",
              "  a boom - a - boomerang is love \n",
              " \n",
              " \n",
              "y: LMLabelList\n",
              ",,,,\n",
              "Path: .;\n",
              "\n",
              "Valid: LabelList (200 items)\n",
              "x: LMTextList\n",
              "xxbos i ride an old paint , i lead an old xxunk \n",
              "  i 'm goin' to xxmaj xxunk to throw the xxunk \n",
              "  xxmaj they feed in the xxunk , they water in the draw \n",
              "  xxmaj their tails are all xxunk , their xxunk are all xxunk \n",
              " \n",
              "  xxmaj chorus : \n",
              "  xxmaj ride around little xxunk , ride around them slow \n",
              "  xxmaj for the xxunk and xxunk are xxunk ' to go \n",
              " \n",
              "  xxmaj old xxmaj bill xxmaj jones had a daughter and a son \n",
              "  xxmaj one went to xxunk , the other went wrong \n",
              "  xxmaj his wife , she got killed in a xxunk fight \n",
              "  xxmaj but still he 's a - singin ' from mornin ' till night \n",
              " \n",
              "  xxmaj chorus \n",
              " \n",
              "  xxmaj when i die , take my saddle from the wall \n",
              "  xxmaj place it on my old pony , lead him out of his xxunk \n",
              "  xxmaj tie my bones to my saddle and turn our faces to the xxmaj west \n",
              "  xxmaj and we 'll ride the xxunk we love the best \n",
              " \n",
              "  xxmaj chorus \n",
              " \n",
              "  i ride an old paint , i lead an old xxunk \n",
              "  i 'm goin' to xxmaj xxunk to throw the xxunk \n",
              "  xxmaj they feed in the xxunk , they water in the draw \n",
              "  xxmaj their tails are all xxunk , and their xxunk are all xxunk \n",
              " \n",
              "  xxmaj chorus \n",
              " \n",
              " ,xxbos xxmaj we are climbing xxmaj xxunk 's ladder \n",
              "  xxmaj we are climbing xxmaj xxunk 's ladder \n",
              "  xxmaj we are climbing xxmaj xxunk 's ladder \n",
              "  xxmaj brothers , sisters , all \n",
              " \n",
              "  xxmaj every xxunk goes higher and higher \n",
              "  xxmaj every xxunk goes higher and higher \n",
              "  xxmaj every xxunk goes higher and higher \n",
              "  xxmaj brothers , sisters , all \n",
              " \n",
              "  xxmaj we are dancing xxmaj xxunk 's circle \n",
              "  xxmaj we are dancing xxmaj xxunk 's circle \n",
              "  xxmaj we are dancing xxmaj xxunk 's circle \n",
              "  xxmaj sisters , brothers , all \n",
              " \n",
              "  xxmaj every round a xxunk \n",
              "  xxmaj every round a xxunk \n",
              "  xxmaj every round a xxunk \n",
              "  xxmaj sisters , brothers , all \n",
              " \n",
              "  xxmaj we are climbing xxmaj xxunk 's ladder \n",
              "  xxmaj we are climbing xxmaj xxunk 's ladder \n",
              "  xxmaj we are climbing xxmaj xxunk 's ladder \n",
              "  xxmaj brothers , sisters , all \n",
              " \n",
              " ,xxbos xxmaj down the way where the nights are gay \n",
              "  xxmaj and the sun shines daily on the mountain top \n",
              "  i took a trip on a sailing ship \n",
              "  xxmaj and when i reached xxmaj xxunk i made a stop \n",
              " \n",
              "  [ xxup chorus : ] \n",
              "  xxmaj but i 'm sad to say , i 'm on my way \n",
              "  xxmaj wo n't be back for many a day \n",
              "  xxmaj my heart is down , my head is turning around \n",
              "  i had to leave a little girl in xxmaj xxunk town \n",
              " \n",
              "  xxmaj sounds of laughter everywhere \n",
              "  xxmaj and the dancing girls xxunk to and fro \n",
              "  i must xxunk that my heart is there \n",
              "  xxmaj though i 've been from xxmaj xxunk to xxmaj mexico \n",
              " \n",
              "  [ xxup chorus ] \n",
              "  xxmaj down at the xxunk you can hear \n",
              "  xxmaj ladies cry out while on their head they bear \n",
              "  xxmaj xxunk xxunk and xxunk fish is nice \n",
              "  xxmaj and the xxunk is good any time of year \n",
              " \n",
              "  [ xxup chorus ] \n",
              "  [ xxup chorus ] \n",
              " \n",
              " ,xxbos [ xxup chorus : ] \n",
              "  xxmaj lying on the side of the road \n",
              "  xxmaj feeling like he heard a sound \n",
              "  xxmaj xxunk with the feelin ' that he xxunk \n",
              "  xxmaj john looked down , xxmaj john looked down \n",
              "  xxmaj john looked down the long , long road \n",
              " \n",
              "  xxmaj she gave xxmaj john a present that was fine \n",
              "  xxmaj so fine that he had to go \n",
              "  xxmaj went to see what it was that he xxunk \n",
              "  xxmaj john looked down , xxmaj john looked down \n",
              "  xxmaj john looked down the long , long road \n",
              " \n",
              "  xxmaj and i know it 's hard \n",
              "  xxmaj but what did you expect of her ? \n",
              "  xxmaj john looked down \n",
              " \n",
              "  xxmaj if you see the lady in your mind \n",
              "  xxmaj even in her xxunk \n",
              "  xxmaj standing through the darkest night \n",
              "  xxmaj and the people want to fight \n",
              "  xxmaj but first ask if it 's all right \n",
              "  xxmaj john looked down , xxmaj john looked down \n",
              "  xxmaj john looked down the long , long road \n",
              " \n",
              "  [ xxup chorus ] \n",
              "  xxmaj and i know it 's hard \n",
              "  xxmaj but what did you expect of her ? \n",
              "  xxmaj john looked down \n",
              " \n",
              " ,xxbos xxmaj words and music by xxmaj ed xxunk \n",
              "  xxmaj last night i had the strangest dream \n",
              "  i 'd ever dreamed before \n",
              "  i dreamed the world had all agreed \n",
              "  xxmaj to put an end to war \n",
              "  i dreamed i saw a mighty room \n",
              "  xxmaj filled with women and men \n",
              "  xxmaj and the paper they were xxunk said \n",
              "  xxmaj they 'd never fight again \n",
              "  xxmaj and when the paper was all signed \n",
              "  xxmaj and a million xxunk made \n",
              "  xxmaj they all xxunk hands and bowed their heads \n",
              "  xxmaj and xxunk xxunk were prayed \n",
              "  xxmaj and the people in the streets below \n",
              "  xxmaj were dancing ' round and ' round \n",
              "  xxmaj while xxunk and guns and xxunk \n",
              "  xxmaj were scattered on the ground \n",
              "  xxmaj last night i had the strangest dream \n",
              "  i 'd never dreamed before \n",
              "  i dreamed the world had all agreed \n",
              "  xxmaj to put an end to war . \n",
              " \n",
              " \n",
              " \n",
              "y: LMLabelList\n",
              ",,,,\n",
              "Path: .;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): AWD_LSTM(\n",
              "    (encoder): Embedding(4360, 400, padding_idx=1)\n",
              "    (encoder_dp): EmbeddingDropout(\n",
              "      (emb): Embedding(4360, 400, padding_idx=1)\n",
              "    )\n",
              "    (rnns): ModuleList(\n",
              "      (0): WeightDropout(\n",
              "        (module): LSTM(400, 1152, batch_first=True)\n",
              "      )\n",
              "      (1): WeightDropout(\n",
              "        (module): LSTM(1152, 1152, batch_first=True)\n",
              "      )\n",
              "      (2): WeightDropout(\n",
              "        (module): LSTM(1152, 400, batch_first=True)\n",
              "      )\n",
              "    )\n",
              "    (input_dp): RNNDropout()\n",
              "    (hidden_dps): ModuleList(\n",
              "      (0): RNNDropout()\n",
              "      (1): RNNDropout()\n",
              "      (2): RNNDropout()\n",
              "    )\n",
              "  )\n",
              "  (1): LinearDecoder(\n",
              "    (decoder): Linear(in_features=400, out_features=4360, bias=True)\n",
              "    (output_dp): RNNDropout()\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f76be47cbf8>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
              "learn: LanguageLearner(data=TextLMDataBunch;\n",
              "\n",
              "Train: LabelList (800 items)\n",
              "x: LMTextList\n",
              "xxbos xxmaj look at her face , it 's a wonderful face \n",
              "  xxmaj and it means something special to me \n",
              "  xxmaj look at the way that she smiles when she sees me \n",
              "  xxmaj how lucky can one fellow be ? \n",
              " \n",
              "  xxmaj she 's just my kind of girl , she makes me feel fine \n",
              "  xxmaj who could ever believe that she could be mine ? \n",
              "  xxmaj she 's just my kind of girl , without her i 'm blue \n",
              "  xxmaj and if she ever leaves me what could i do , what could i do ? \n",
              " \n",
              "  xxmaj and when we go for a walk in the park \n",
              "  xxmaj and she holds me and xxunk my hand \n",
              "  xxmaj we 'll go on walking for hours and talking \n",
              "  xxmaj about all the things that we plan \n",
              " \n",
              "  xxmaj she 's just my kind of girl , she makes me feel fine \n",
              "  xxmaj who could ever believe that she could be mine ? \n",
              "  xxmaj she 's just my kind of girl , without her i 'm blue \n",
              "  xxmaj and if she ever leaves me what could i do , what could i do ? \n",
              " \n",
              " ,xxbos xxmaj take it easy with me , please \n",
              "  xxmaj touch me gently like a summer evening breeze \n",
              "  xxmaj take your time , make it slow \n",
              "  xxmaj andante , xxmaj andante \n",
              "  xxmaj just let the feeling grow \n",
              " \n",
              "  xxmaj make your fingers soft and light \n",
              "  xxmaj let your body be the xxunk of the night \n",
              "  xxmaj touch my soul , you know how \n",
              "  xxmaj andante , xxmaj andante \n",
              "  xxmaj go slowly with me now \n",
              " \n",
              "  i 'm your music \n",
              "  ( i am your music and i am your song ) \n",
              "  i 'm your song \n",
              "  ( i am your music and i am your song ) \n",
              "  xxmaj play me time and time again and make me strong \n",
              "  ( xxmaj play me again 'cause you 're making me strong ) \n",
              "  xxmaj make me sing , make me sound \n",
              "  ( xxmaj you make me sing and you make me ) \n",
              "  xxmaj andante , xxmaj andante \n",
              "  xxmaj tread lightly on my ground \n",
              "  xxmaj andante , xxmaj andante \n",
              "  xxmaj oh please do n't let me down \n",
              " \n",
              "  xxmaj there 's a xxunk in your eyes \n",
              "  xxmaj like the feeling of a thousand butterflies \n",
              "  xxmaj please do n't talk , go on , play \n",
              "  xxmaj andante , xxmaj andante \n",
              "  xxmaj and let me float away \n",
              " \n",
              "  i 'm your music \n",
              "  ( i am your music and i am your song ) \n",
              "  i 'm your song \n",
              "  ( i am your music and i am your song ) \n",
              "  xxmaj play me time and time again and make me strong \n",
              "  ( xxmaj play me again 'cause you 're making me strong ) \n",
              "  xxmaj make me sing , make me sound \n",
              "  ( xxmaj you make me sing and you make me ) \n",
              "  xxmaj andante , xxmaj andante \n",
              "  xxmaj tread lightly on my ground \n",
              "  xxmaj andante , xxmaj andante \n",
              "  xxmaj oh please do n't let me down \n",
              " \n",
              "  xxmaj make me sing , make me sound \n",
              "  ( xxmaj you make me sing and you make me ) \n",
              "  xxmaj andante , xxmaj andante \n",
              "  xxmaj tread lightly on my ground \n",
              "  xxmaj andante , xxmaj andante \n",
              "  xxmaj oh please do n't let me down \n",
              "  xxmaj andante , xxmaj andante \n",
              "  xxmaj oh please do n't let me down \n",
              " \n",
              " ,xxbos i 'll never know why i had to go \n",
              "  xxmaj why i had to put up such a lousy rotten show \n",
              "  xxmaj boy , i was tough , packing all my stuff \n",
              "  xxmaj saying i do n't need you anymore , i 've had enough \n",
              "  xxmaj and now , look at me standing here again 'cause i found out that \n",
              "  xxmaj ma xxwrep 15 ma my life is here \n",
              "  xxmaj got ta have you near \n",
              " \n",
              "  xxmaj as good as new , my love for you \n",
              "  xxmaj and keeping it that way is my intention \n",
              "  xxmaj as good as new and growing too \n",
              "  xxmaj yes , i think it 's taking on a new dimension \n",
              "  xxmaj it 's as good as new , my love for you \n",
              "  xxmaj just like it used to be and even better \n",
              "  xxmaj as good as new , thank xxmaj god it 's true \n",
              "  xxmaj darling , we were always meant to stay together \n",
              " \n",
              "  xxmaj feel like a xxunk , never felt so cheap \n",
              "  xxmaj never had a notion that my love could be so deep \n",
              "  xxmaj how could i make such a dumb mistake \n",
              "  xxmaj now i know i 'm not xxunk to another break \n",
              "  xxmaj but please , baby , i beg you to forgive 'cause i found out that \n",
              "  xxmaj ma xxwrep 15 ma my life is here \n",
              "  xxmaj got ta get you near \n",
              " \n",
              "  i thought that our love was at an end but here i am again \n",
              " \n",
              "  xxmaj as good as new , my love for you \n",
              "  xxmaj and keeping it that way is my intention \n",
              "  xxmaj as good as new and growing too \n",
              "  xxmaj yes , i think it 's taking on a new dimension \n",
              "  xxmaj it 's as good as new , my love for you \n",
              "  xxmaj just like it used to be and even better \n",
              "  xxmaj as good as new , thank xxmaj god it 's true \n",
              "  xxmaj darling , we were always meant to stay together \n",
              " \n",
              "  xxmaj yes the love i have for you feels as good as new \n",
              "  xxmaj darling , we were always meant to stay together \n",
              " \n",
              " ,xxbos xxmaj making somebody happy is a question of give and take \n",
              "  xxmaj you can learn how to show it so come on , give yourself a break \n",
              "  xxmaj every smile and every little touch \n",
              "  xxmaj do n't you know that they mean so much \n",
              "  xxmaj sweet sweet kisses so tender \n",
              "  xxmaj always will return to sender \n",
              " \n",
              "  xxmaj like a bang , a boom - a - boomerang \n",
              "  xxmaj dum - be - dum - dum be - dum - be - dum - dum \n",
              "  xxmaj oh bang , a boom - a - boomerang \n",
              "  xxmaj love is a tune you hum - de - hum - hum \n",
              "  xxmaj so give it away , i think you 'll learn \n",
              "  xxmaj you 'll get love in return \n",
              "  xxmaj so bang , a boom - a - boomerang is love \n",
              "  a boom - a - boomerang is love \n",
              " \n",
              "  xxmaj love is always around and you can look for it anywhere \n",
              "  xxmaj when you feel that you 've found it my advice is to take good care \n",
              "  xxmaj never use it as a selfish tool \n",
              "  xxmaj never ever be such a fool \n",
              "  xxmaj every feeling you 're showing \n",
              "  xxmaj is a boomerang you 're throwing \n",
              " \n",
              "  xxmaj yes a bang , a boom - a - boomerang \n",
              "  xxmaj dum - be - dum - dum be - dum - be - dum - dum \n",
              "  xxmaj oh bang , a boom - a - boomerang \n",
              "  xxmaj love is a tune you hum - de - hum - hum \n",
              "  xxmaj so give it away , i think you 'll learn \n",
              "  xxmaj you 'll get love in return \n",
              "  xxmaj so bang , a boom - a - boomerang is love \n",
              " \n",
              "  xxmaj and if you 're warm and tender \n",
              "  i 'll kiss you , return to sender \n",
              "  xxmaj please surrender \n",
              " \n",
              "  xxmaj bang , a boom - a - boomerang \n",
              "  xxmaj dum - be - dum - dum be - dum - be - dum - dum \n",
              "  xxmaj oh bang , a boom - a - boomerang is love \n",
              "  a boom - a - boomerang is love \n",
              " \n",
              " ,xxbos xxmaj making somebody happy is a question of give and take \n",
              "  xxmaj you can learn how to show it so come on , give yourself a break \n",
              "  xxmaj every smile and every little touch \n",
              "  xxmaj do n't you know that they mean so much \n",
              "  xxmaj sweet sweet kisses so tender \n",
              "  xxmaj always will return to sender \n",
              " \n",
              "  xxmaj like a bang , a boom - a - boomerang \n",
              "  xxmaj dumb - be - dumb - dumb be - dumb - be - dumb - dumb \n",
              "  xxmaj oh bang , a boom - a - boomerang \n",
              "  xxmaj love is a tune you hum - de - hum - hum \n",
              "  xxmaj by giving away , i think you 'll learn \n",
              "  xxmaj you 'll get love in return \n",
              "  xxmaj so bang , a boom - a - boomerang is love \n",
              "  a boom - a - boomerang is love \n",
              " \n",
              "  xxmaj love is always around and you can look for it anywhere \n",
              "  xxmaj when you feel that you 've found it my advice is to take good care \n",
              "  xxmaj never use it as a selfish tool \n",
              "  xxmaj never ever be such a fool \n",
              "  xxmaj every feeling you 're showing \n",
              "  xxmaj is a boomerang you 're throwing \n",
              " \n",
              "  xxmaj yes a bang , a boom - a - boomerang \n",
              "  xxmaj dumb - be - dumb - dumb be - dumb - be - dumb - dumb \n",
              "  xxmaj oh bang , a boom - a - boomerang \n",
              "  xxmaj love is a tune you hum - de - hum - hum \n",
              "  xxmaj by giving away , i think you 'll learn \n",
              "  xxmaj you 'll get love in return \n",
              "  xxmaj so bang , a boom - a - boomerang is love \n",
              " \n",
              "  xxmaj and if you 're warm and tender \n",
              "  i 'll kiss you , return to sender \n",
              "  xxmaj please surrender \n",
              " \n",
              "  xxmaj bang , a boom - a - boomerang \n",
              "  xxmaj dumb - be - dumb - dumb be - dumb - be - dumb - dumb \n",
              "  xxmaj oh bang , a boom - a - boomerang is love \n",
              "  a boom - a - boomerang is love \n",
              " \n",
              " \n",
              "y: LMLabelList\n",
              ",,,,\n",
              "Path: .;\n",
              "\n",
              "Valid: LabelList (200 items)\n",
              "x: LMTextList\n",
              "xxbos i ride an old paint , i lead an old xxunk \n",
              "  i 'm goin' to xxmaj xxunk to throw the xxunk \n",
              "  xxmaj they feed in the xxunk , they water in the draw \n",
              "  xxmaj their tails are all xxunk , their xxunk are all xxunk \n",
              " \n",
              "  xxmaj chorus : \n",
              "  xxmaj ride around little xxunk , ride around them slow \n",
              "  xxmaj for the xxunk and xxunk are xxunk ' to go \n",
              " \n",
              "  xxmaj old xxmaj bill xxmaj jones had a daughter and a son \n",
              "  xxmaj one went to xxunk , the other went wrong \n",
              "  xxmaj his wife , she got killed in a xxunk fight \n",
              "  xxmaj but still he 's a - singin ' from mornin ' till night \n",
              " \n",
              "  xxmaj chorus \n",
              " \n",
              "  xxmaj when i die , take my saddle from the wall \n",
              "  xxmaj place it on my old pony , lead him out of his xxunk \n",
              "  xxmaj tie my bones to my saddle and turn our faces to the xxmaj west \n",
              "  xxmaj and we 'll ride the xxunk we love the best \n",
              " \n",
              "  xxmaj chorus \n",
              " \n",
              "  i ride an old paint , i lead an old xxunk \n",
              "  i 'm goin' to xxmaj xxunk to throw the xxunk \n",
              "  xxmaj they feed in the xxunk , they water in the draw \n",
              "  xxmaj their tails are all xxunk , and their xxunk are all xxunk \n",
              " \n",
              "  xxmaj chorus \n",
              " \n",
              " ,xxbos xxmaj we are climbing xxmaj xxunk 's ladder \n",
              "  xxmaj we are climbing xxmaj xxunk 's ladder \n",
              "  xxmaj we are climbing xxmaj xxunk 's ladder \n",
              "  xxmaj brothers , sisters , all \n",
              " \n",
              "  xxmaj every xxunk goes higher and higher \n",
              "  xxmaj every xxunk goes higher and higher \n",
              "  xxmaj every xxunk goes higher and higher \n",
              "  xxmaj brothers , sisters , all \n",
              " \n",
              "  xxmaj we are dancing xxmaj xxunk 's circle \n",
              "  xxmaj we are dancing xxmaj xxunk 's circle \n",
              "  xxmaj we are dancing xxmaj xxunk 's circle \n",
              "  xxmaj sisters , brothers , all \n",
              " \n",
              "  xxmaj every round a xxunk \n",
              "  xxmaj every round a xxunk \n",
              "  xxmaj every round a xxunk \n",
              "  xxmaj sisters , brothers , all \n",
              " \n",
              "  xxmaj we are climbing xxmaj xxunk 's ladder \n",
              "  xxmaj we are climbing xxmaj xxunk 's ladder \n",
              "  xxmaj we are climbing xxmaj xxunk 's ladder \n",
              "  xxmaj brothers , sisters , all \n",
              " \n",
              " ,xxbos xxmaj down the way where the nights are gay \n",
              "  xxmaj and the sun shines daily on the mountain top \n",
              "  i took a trip on a sailing ship \n",
              "  xxmaj and when i reached xxmaj xxunk i made a stop \n",
              " \n",
              "  [ xxup chorus : ] \n",
              "  xxmaj but i 'm sad to say , i 'm on my way \n",
              "  xxmaj wo n't be back for many a day \n",
              "  xxmaj my heart is down , my head is turning around \n",
              "  i had to leave a little girl in xxmaj xxunk town \n",
              " \n",
              "  xxmaj sounds of laughter everywhere \n",
              "  xxmaj and the dancing girls xxunk to and fro \n",
              "  i must xxunk that my heart is there \n",
              "  xxmaj though i 've been from xxmaj xxunk to xxmaj mexico \n",
              " \n",
              "  [ xxup chorus ] \n",
              "  xxmaj down at the xxunk you can hear \n",
              "  xxmaj ladies cry out while on their head they bear \n",
              "  xxmaj xxunk xxunk and xxunk fish is nice \n",
              "  xxmaj and the xxunk is good any time of year \n",
              " \n",
              "  [ xxup chorus ] \n",
              "  [ xxup chorus ] \n",
              " \n",
              " ,xxbos [ xxup chorus : ] \n",
              "  xxmaj lying on the side of the road \n",
              "  xxmaj feeling like he heard a sound \n",
              "  xxmaj xxunk with the feelin ' that he xxunk \n",
              "  xxmaj john looked down , xxmaj john looked down \n",
              "  xxmaj john looked down the long , long road \n",
              " \n",
              "  xxmaj she gave xxmaj john a present that was fine \n",
              "  xxmaj so fine that he had to go \n",
              "  xxmaj went to see what it was that he xxunk \n",
              "  xxmaj john looked down , xxmaj john looked down \n",
              "  xxmaj john looked down the long , long road \n",
              " \n",
              "  xxmaj and i know it 's hard \n",
              "  xxmaj but what did you expect of her ? \n",
              "  xxmaj john looked down \n",
              " \n",
              "  xxmaj if you see the lady in your mind \n",
              "  xxmaj even in her xxunk \n",
              "  xxmaj standing through the darkest night \n",
              "  xxmaj and the people want to fight \n",
              "  xxmaj but first ask if it 's all right \n",
              "  xxmaj john looked down , xxmaj john looked down \n",
              "  xxmaj john looked down the long , long road \n",
              " \n",
              "  [ xxup chorus ] \n",
              "  xxmaj and i know it 's hard \n",
              "  xxmaj but what did you expect of her ? \n",
              "  xxmaj john looked down \n",
              " \n",
              " ,xxbos xxmaj words and music by xxmaj ed xxunk \n",
              "  xxmaj last night i had the strangest dream \n",
              "  i 'd ever dreamed before \n",
              "  i dreamed the world had all agreed \n",
              "  xxmaj to put an end to war \n",
              "  i dreamed i saw a mighty room \n",
              "  xxmaj filled with women and men \n",
              "  xxmaj and the paper they were xxunk said \n",
              "  xxmaj they 'd never fight again \n",
              "  xxmaj and when the paper was all signed \n",
              "  xxmaj and a million xxunk made \n",
              "  xxmaj they all xxunk hands and bowed their heads \n",
              "  xxmaj and xxunk xxunk were prayed \n",
              "  xxmaj and the people in the streets below \n",
              "  xxmaj were dancing ' round and ' round \n",
              "  xxmaj while xxunk and guns and xxunk \n",
              "  xxmaj were scattered on the ground \n",
              "  xxmaj last night i had the strangest dream \n",
              "  i 'd never dreamed before \n",
              "  i dreamed the world had all agreed \n",
              "  xxmaj to put an end to war . \n",
              " \n",
              " \n",
              " \n",
              "y: LMLabelList\n",
              ",,,,\n",
              "Path: .;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): AWD_LSTM(\n",
              "    (encoder): Embedding(4360, 400, padding_idx=1)\n",
              "    (encoder_dp): EmbeddingDropout(\n",
              "      (emb): Embedding(4360, 400, padding_idx=1)\n",
              "    )\n",
              "    (rnns): ModuleList(\n",
              "      (0): WeightDropout(\n",
              "        (module): LSTM(400, 1152, batch_first=True)\n",
              "      )\n",
              "      (1): WeightDropout(\n",
              "        (module): LSTM(1152, 1152, batch_first=True)\n",
              "      )\n",
              "      (2): WeightDropout(\n",
              "        (module): LSTM(1152, 400, batch_first=True)\n",
              "      )\n",
              "    )\n",
              "    (input_dp): RNNDropout()\n",
              "    (hidden_dps): ModuleList(\n",
              "      (0): RNNDropout()\n",
              "      (1): RNNDropout()\n",
              "      (2): RNNDropout()\n",
              "    )\n",
              "  )\n",
              "  (1): LinearDecoder(\n",
              "    (decoder): Linear(in_features=400, out_features=4360, bias=True)\n",
              "    (output_dp): RNNDropout()\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f76be47cbf8>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): Embedding(4360, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(4360, 400, padding_idx=1)\n",
              "  )\n",
              "  (2): LinearDecoder(\n",
              "    (decoder): Linear(in_features=400, out_features=4360, bias=True)\n",
              "    (output_dp): RNNDropout()\n",
              "  )\n",
              ")], add_time=True, silent=False)\n",
              "alpha: 2.0\n",
              "beta: 1.0], layer_groups=[Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): Embedding(4360, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(4360, 400, padding_idx=1)\n",
              "  )\n",
              "  (2): LinearDecoder(\n",
              "    (decoder): Linear(in_features=400, out_features=4360, bias=True)\n",
              "    (output_dp): RNNDropout()\n",
              "  )\n",
              ")], add_time=True, silent=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNqtODnCe3B9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bz904m8be2-8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT = \"we are learning transfer learning\"\n",
        "N_WORDS = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4gyxeQae271",
        "colab_type": "code",
        "outputId": "fb31347e-a3bc-403d-f600-70d9408878f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "poem = learntest.predict(TEXT, N_WORDS, temperature = 0.75)\n",
        "print(poem)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "we are learning transfer learning \n",
            "  In our care \n",
            "  There 's only one so able \n",
            "  Could anyone believe \n",
            "  To be understood and advised \n",
            "  To step closer than the ones to our land \n",
            "  As we walk away \n",
            "  As we walk away \n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlreB9UnpyUH",
        "colab_type": "code",
        "outputId": "caec98e8-418f-4360-d75f-8c50ff1387b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "poem"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"we are learning transfer learning \\n  In our care \\n  There 's only one so able \\n  Could anyone believe \\n  To be understood and advised \\n  To step closer than the ones to our land \\n  As we walk away \\n  As we walk away \\n \""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xlW2zr8p3-_",
        "colab_type": "code",
        "outputId": "992a8b18-d5b7-4d0a-e500-7ec7d93e7690",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        }
      },
      "source": [
        "!pip install gtts"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gtts\n",
            "  Downloading https://files.pythonhosted.org/packages/02/0b/e19dd65623e34954fb6793765ad1c6185a669a33e6a6245939e97abeaaca/gTTS-2.0.4-py3-none-any.whl\n",
            "Collecting gtts-token>=1.1.3\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/25/ca6e9cd3275bfc3097fe6b06cc31db6d3dfaf32e032e0f73fead9c9a03ce/gTTS-token-1.1.3.tar.gz\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gtts) (2.21.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gtts) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from gtts) (7.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from gtts) (4.6.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gtts) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gtts) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gtts) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gtts) (2019.9.11)\n",
            "Building wheels for collected packages: gtts-token\n",
            "  Building wheel for gtts-token (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gtts-token: filename=gTTS_token-1.1.3-cp36-none-any.whl size=4097 sha256=1b5037e2e6f6acfc04fd79d74ad3898e2b83b6ea6cb3398167eb523819fbbfb3\n",
            "  Stored in directory: /root/.cache/pip/wheels/dd/11/61/33f7e51bf545e910552b2255eead2a7cd8ef54064b46dceb34\n",
            "Successfully built gtts-token\n",
            "Installing collected packages: gtts-token, gtts\n",
            "Successfully installed gtts-2.0.4 gtts-token-1.1.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_Tj3CWQpySP",
        "colab_type": "code",
        "outputId": "c099911d-dd64-4d7e-b800-1d0b2d8d20d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from gtts import gTTS\n",
        "import os\n",
        "tts = gTTS(text=poem, lang='en')\n",
        "tts.save(\"good.mp3\")\n",
        "os.system(\"mpg321 good.mp3\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32512"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKeZZ1eXpyOz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tts = gTTS(poem, lang='en')\n",
        "tts.save('poem.wav')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9r2oNj1ybMt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43St79iryM3g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATAPATH = '.'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydBpmG-dziaA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pMcRPwCWzirW",
        "outputId": "cb922e8d-4dba-4a69-bad6-bcb098ddc2f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "data_lm.vocab.itos"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['xxunk',\n",
              " 'xxpad',\n",
              " 'xxbos',\n",
              " 'xxeos',\n",
              " 'xxfld',\n",
              " 'xxmaj',\n",
              " 'xxup',\n",
              " 'xxrep',\n",
              " 'xxwrep',\n",
              " '\\n ',\n",
              " 'i',\n",
              " 'the',\n",
              " ',',\n",
              " 'you',\n",
              " '\\n \\n ',\n",
              " 'to',\n",
              " 'and',\n",
              " 'a',\n",
              " 'it',\n",
              " 'me',\n",
              " \"'s\",\n",
              " \"n't\",\n",
              " 'in',\n",
              " 'my',\n",
              " 'of',\n",
              " 'that',\n",
              " 'do',\n",
              " 'we',\n",
              " 'your',\n",
              " 'on',\n",
              " 'all',\n",
              " 'love',\n",
              " \"'\",\n",
              " 'is',\n",
              " 'be',\n",
              " \"'m\",\n",
              " 'for',\n",
              " 'so',\n",
              " \"'re\",\n",
              " 'when',\n",
              " 'just',\n",
              " '.',\n",
              " 'but',\n",
              " '-',\n",
              " 'with',\n",
              " 'know',\n",
              " 'no',\n",
              " 'got',\n",
              " 'there',\n",
              " '(',\n",
              " ')',\n",
              " 'can',\n",
              " \"'ll\",\n",
              " 'if',\n",
              " 'like',\n",
              " 'what',\n",
              " 'now',\n",
              " 'one',\n",
              " 'was',\n",
              " 'down',\n",
              " 'she',\n",
              " 'time',\n",
              " \"'ve\",\n",
              " 'are',\n",
              " 'na',\n",
              " 'never',\n",
              " 'see',\n",
              " 'this',\n",
              " 'have',\n",
              " 'he',\n",
              " 'up',\n",
              " 'out',\n",
              " 'go',\n",
              " 'oh',\n",
              " 'let',\n",
              " 'get',\n",
              " 'ca',\n",
              " 'take',\n",
              " 'want',\n",
              " 'they',\n",
              " 'baby',\n",
              " 'come',\n",
              " 'will',\n",
              " 'at',\n",
              " 'away',\n",
              " 'as',\n",
              " 'gon',\n",
              " 'say',\n",
              " 'way',\n",
              " 'more',\n",
              " 'not',\n",
              " '?',\n",
              " 'here',\n",
              " 'from',\n",
              " 'yeah',\n",
              " 'could',\n",
              " 'make',\n",
              " 'night',\n",
              " 'day',\n",
              " 'how',\n",
              " 'too',\n",
              " 'tell',\n",
              " 'where',\n",
              " 'life',\n",
              " 'heart',\n",
              " 'feel',\n",
              " 'her',\n",
              " 'man',\n",
              " 'through',\n",
              " 'back',\n",
              " 'by',\n",
              " 'give',\n",
              " 'little',\n",
              " 'only',\n",
              " 'need',\n",
              " 'our',\n",
              " 'chorus',\n",
              " \"'d\",\n",
              " 'right',\n",
              " 'la',\n",
              " 'been',\n",
              " 'well',\n",
              " '...',\n",
              " 'then',\n",
              " '[',\n",
              " ']',\n",
              " 'some',\n",
              " 'world',\n",
              " 'ai',\n",
              " 'said',\n",
              " 'who',\n",
              " 'wo',\n",
              " 'would',\n",
              " 'always',\n",
              " 'had',\n",
              " 'every',\n",
              " 'still',\n",
              " 'or',\n",
              " 'us',\n",
              " 'good',\n",
              " 'think',\n",
              " 'again',\n",
              " \"'cause\",\n",
              " 'long',\n",
              " 'old',\n",
              " 'eyes',\n",
              " 'his',\n",
              " 'over',\n",
              " 'did',\n",
              " 'girl',\n",
              " 'find',\n",
              " 'ta',\n",
              " 'look',\n",
              " 'really',\n",
              " 'nothing',\n",
              " 'much',\n",
              " 'live',\n",
              " 'hear',\n",
              " 'around',\n",
              " 'why',\n",
              " 'mind',\n",
              " 'were',\n",
              " '\"',\n",
              " 'hey',\n",
              " 'people',\n",
              " 'things',\n",
              " 'tonight',\n",
              " 'am',\n",
              " 'home',\n",
              " 'better',\n",
              " 'hard',\n",
              " 'ever',\n",
              " 'before',\n",
              " 'hold',\n",
              " 'believe',\n",
              " 'walk',\n",
              " '!',\n",
              " 'an',\n",
              " 'alone',\n",
              " 'turn',\n",
              " 'about',\n",
              " 'sweet',\n",
              " 'stay',\n",
              " 'light',\n",
              " 'new',\n",
              " 'into',\n",
              " ':',\n",
              " 'hand',\n",
              " 'try',\n",
              " 'made',\n",
              " 'feeling',\n",
              " 'stop',\n",
              " 'true',\n",
              " 'sun',\n",
              " 'has',\n",
              " 'please',\n",
              " 'gone',\n",
              " 'lord',\n",
              " 'head',\n",
              " 'him',\n",
              " 'side',\n",
              " 'someone',\n",
              " 'yes',\n",
              " 'something',\n",
              " 'them',\n",
              " 'far',\n",
              " 'must',\n",
              " 'keep',\n",
              " 'sing',\n",
              " 'ah',\n",
              " 'those',\n",
              " 'together',\n",
              " 'everything',\n",
              " 'fire',\n",
              " 'face',\n",
              " 'even',\n",
              " 'thing',\n",
              " 'place',\n",
              " 'last',\n",
              " 'remember',\n",
              " 'without',\n",
              " 'forever',\n",
              " 'honey',\n",
              " 'show',\n",
              " 'than',\n",
              " 'road',\n",
              " 'inside',\n",
              " 'call',\n",
              " 'fall',\n",
              " 'put',\n",
              " 'alive',\n",
              " 'woman',\n",
              " 'enough',\n",
              " 'play',\n",
              " 'leave',\n",
              " 'chance',\n",
              " 'god',\n",
              " 'another',\n",
              " 'two',\n",
              " 'morning',\n",
              " 'round',\n",
              " 'cause',\n",
              " 'waiting',\n",
              " 'may',\n",
              " 'their',\n",
              " 'wrong',\n",
              " 'blue',\n",
              " 'wanna',\n",
              " 'while',\n",
              " 'cry',\n",
              " 'dream',\n",
              " 'does',\n",
              " 'end',\n",
              " 'free',\n",
              " 'days',\n",
              " 'door',\n",
              " 'close',\n",
              " 'done',\n",
              " 'other',\n",
              " 'dance',\n",
              " 'die',\n",
              " 'same',\n",
              " 'left',\n",
              " 'sometimes',\n",
              " 'run',\n",
              " 'soul',\n",
              " 'lonely',\n",
              " 'mine',\n",
              " 'once',\n",
              " 'song',\n",
              " 'smile',\n",
              " 'off',\n",
              " 'easy',\n",
              " 'care',\n",
              " 'dreams',\n",
              " 'hope',\n",
              " 'should',\n",
              " 'name',\n",
              " 'thought',\n",
              " 'today',\n",
              " 'friend',\n",
              " 'many',\n",
              " 'these',\n",
              " 'high',\n",
              " 'each',\n",
              " 'comes',\n",
              " 'goodbye',\n",
              " 'nights',\n",
              " 'after',\n",
              " 'till',\n",
              " 'boy',\n",
              " 'line',\n",
              " 'own',\n",
              " 'going',\n",
              " 'bad',\n",
              " 'sure',\n",
              " 'christmas',\n",
              " 'nobody',\n",
              " 'late',\n",
              " 'cold',\n",
              " 'real',\n",
              " 'wind',\n",
              " 'words',\n",
              " 'living',\n",
              " 'walking',\n",
              " 'found',\n",
              " 'break',\n",
              " 'kiss',\n",
              " 'rain',\n",
              " 'came',\n",
              " 'happy',\n",
              " 'seems',\n",
              " 'help',\n",
              " 'years',\n",
              " 'times',\n",
              " '4',\n",
              " 'kind',\n",
              " 'lose',\n",
              " 'knew',\n",
              " 'best',\n",
              " 'nice',\n",
              " 'first',\n",
              " 'music',\n",
              " 'wait',\n",
              " 'o',\n",
              " 'myself',\n",
              " 'looking',\n",
              " 'wish',\n",
              " 'touch',\n",
              " 'somebody',\n",
              " 'city',\n",
              " 'pain',\n",
              " 'sky',\n",
              " 'maybe',\n",
              " 'friends',\n",
              " 'told',\n",
              " 'bit',\n",
              " 'arms',\n",
              " 'upon',\n",
              " 'change',\n",
              " 'ya',\n",
              " 'lay',\n",
              " 'heaven',\n",
              " \"goin'\",\n",
              " 'might',\n",
              " '\\n \\n \\n ',\n",
              " 'watch',\n",
              " 'lights',\n",
              " 'miss',\n",
              " 'though',\n",
              " 'crazy',\n",
              " 'river',\n",
              " 'moon',\n",
              " 'dead',\n",
              " 'shame',\n",
              " 'knows',\n",
              " 'fly',\n",
              " 'behind',\n",
              " 'open',\n",
              " 'bring',\n",
              " 'lost',\n",
              " 'start',\n",
              " 'goes',\n",
              " 'very',\n",
              " 'under',\n",
              " 'coming',\n",
              " 'air',\n",
              " 'wonder',\n",
              " 'used',\n",
              " 'roll',\n",
              " 'calling',\n",
              " 'talk',\n",
              " 'anymore',\n",
              " 'mother',\n",
              " 'strong',\n",
              " 'deep',\n",
              " 'lies',\n",
              " 'any',\n",
              " 'town',\n",
              " 'across',\n",
              " 'fool',\n",
              " 'part',\n",
              " 'young',\n",
              " 'somewhere',\n",
              " 'ha',\n",
              " 'money',\n",
              " 'until',\n",
              " 'tears',\n",
              " 'everybody',\n",
              " 'big',\n",
              " 'hide',\n",
              " 'stand',\n",
              " 'thinking',\n",
              " 'soon',\n",
              " 'understand',\n",
              " 'gimme',\n",
              " 'livin',\n",
              " 'fine',\n",
              " 'ride',\n",
              " 'falling',\n",
              " 'hell',\n",
              " 'mean',\n",
              " 'matter',\n",
              " 'along',\n",
              " 'game',\n",
              " 'clear',\n",
              " 'doctor',\n",
              " 'sa',\n",
              " 'fun',\n",
              " 'near',\n",
              " 'darling',\n",
              " 'listen',\n",
              " 'reason',\n",
              " 'else',\n",
              " 'ang',\n",
              " 'saw',\n",
              " 'pretty',\n",
              " 'dark',\n",
              " 'shine',\n",
              " 'summer',\n",
              " 'sleep',\n",
              " 'lot',\n",
              " 'heard',\n",
              " 'gave',\n",
              " 'making',\n",
              " 'yourself',\n",
              " 'dancing',\n",
              " 'voice',\n",
              " 'ring',\n",
              " 'ready',\n",
              " 'sorry',\n",
              " 'follow',\n",
              " '5',\n",
              " \"lovin'\",\n",
              " 'sound',\n",
              " 'shadows',\n",
              " 'hot',\n",
              " 'water',\n",
              " 'went',\n",
              " 'moment',\n",
              " 'forgive',\n",
              " 'memories',\n",
              " 'seem',\n",
              " 'gets',\n",
              " 'whole',\n",
              " 'slow',\n",
              " 'seen',\n",
              " 'tight',\n",
              " 'tried',\n",
              " 'giving',\n",
              " 'father',\n",
              " 'meet',\n",
              " 'stars',\n",
              " 'ooh',\n",
              " 'its',\n",
              " 'body',\n",
              " 'felt',\n",
              " 'fight',\n",
              " 'knowing',\n",
              " 'move',\n",
              " 'trying',\n",
              " 'since',\n",
              " 'angels',\n",
              " 'alright',\n",
              " 'taking',\n",
              " 'hearts',\n",
              " 'tomorrow',\n",
              " 'broken',\n",
              " 'doing',\n",
              " 'lie',\n",
              " 'room',\n",
              " 'children',\n",
              " 'fear',\n",
              " 'lovers',\n",
              " 'wants',\n",
              " 'country',\n",
              " 'faith',\n",
              " 'queen',\n",
              " 'rock',\n",
              " 'read',\n",
              " 'ask',\n",
              " 'fill',\n",
              " 'jesus',\n",
              " 'bed',\n",
              " 'forget',\n",
              " 'dear',\n",
              " 'mama',\n",
              " 'makes',\n",
              " 'warm',\n",
              " 'being',\n",
              " 'took',\n",
              " 'guess',\n",
              " 'middle',\n",
              " 'apart',\n",
              " 'snow',\n",
              " 'train',\n",
              " 'oo',\n",
              " 'such',\n",
              " 'playing',\n",
              " 'truth',\n",
              " 'perfect',\n",
              " 'swear',\n",
              " 'learn',\n",
              " 'leaving',\n",
              " 'above',\n",
              " 'year',\n",
              " 'floor',\n",
              " 'black',\n",
              " 'sea',\n",
              " 'set',\n",
              " 'hands',\n",
              " 'burning',\n",
              " 'sad',\n",
              " 'afraid',\n",
              " 'midnight',\n",
              " 'between',\n",
              " 'laugh',\n",
              " 'because',\n",
              " 'edge',\n",
              " 'uh',\n",
              " 'cow',\n",
              " 'ground',\n",
              " 'feet',\n",
              " 'land',\n",
              " 'spend',\n",
              " 'blues',\n",
              " 'share',\n",
              " 'everyone',\n",
              " 'born',\n",
              " 'outta',\n",
              " 'standing',\n",
              " 'power',\n",
              " 'shining',\n",
              " 'lady',\n",
              " 'shoes',\n",
              " 'songs',\n",
              " 'dog',\n",
              " 'glad',\n",
              " 'most',\n",
              " 'scream',\n",
              " 'lead',\n",
              " 'fast',\n",
              " 'mountain',\n",
              " 'pink',\n",
              " 'blind',\n",
              " 'king',\n",
              " 'bright',\n",
              " 'win',\n",
              " 'lives',\n",
              " 'hurt',\n",
              " 'magic',\n",
              " 'boys',\n",
              " 'rest',\n",
              " 'ways',\n",
              " 'wanted',\n",
              " 'cool',\n",
              " 'getting',\n",
              " \"'em\",\n",
              " 'says',\n",
              " 'pay',\n",
              " 'girls',\n",
              " 'feelin',\n",
              " 'comin',\n",
              " 'dumb',\n",
              " 'child',\n",
              " 'star',\n",
              " 'darkness',\n",
              " 'outside',\n",
              " 'sight',\n",
              " 'loved',\n",
              " 'running',\n",
              " 'lookin',\n",
              " 'lover',\n",
              " 'longer',\n",
              " 'babe',\n",
              " 'blood',\n",
              " 'leaves',\n",
              " 'eye',\n",
              " 'past',\n",
              " 'white',\n",
              " 'weather',\n",
              " 'rainbow',\n",
              " 'turned',\n",
              " 'both',\n",
              " 'eat',\n",
              " 'word',\n",
              " 'gun',\n",
              " 'peace',\n",
              " 'street',\n",
              " 'work',\n",
              " 'fernando',\n",
              " 'repeat',\n",
              " 'sand',\n",
              " 'hurry',\n",
              " 'tree',\n",
              " 'rich',\n",
              " 'rise',\n",
              " 'thank',\n",
              " 'hour',\n",
              " 'low',\n",
              " 'beat',\n",
              " 'loud',\n",
              " 'watching',\n",
              " 'fell',\n",
              " 'taste',\n",
              " 'daddy',\n",
              " 'rather',\n",
              " 'cross',\n",
              " 'blow',\n",
              " 'belong',\n",
              " 'winter',\n",
              " 'answer',\n",
              " 'key',\n",
              " 'spirit',\n",
              " 'blame',\n",
              " 'full',\n",
              " 'holding',\n",
              " 'throw',\n",
              " 'walked',\n",
              " 'hang',\n",
              " 'beside',\n",
              " 'buy',\n",
              " 'red',\n",
              " 'stone',\n",
              " 'shit',\n",
              " 'thousand',\n",
              " 'dum',\n",
              " 'use',\n",
              " 'hate',\n",
              " 'house',\n",
              " 'yet',\n",
              " 'beyond',\n",
              " 'speak',\n",
              " 'needs',\n",
              " 'empty',\n",
              " 'known',\n",
              " 'sail',\n",
              " 'price',\n",
              " 'worth',\n",
              " 'p',\n",
              " \"'bout\",\n",
              " 'ko',\n",
              " 's',\n",
              " 'trust',\n",
              " 'party',\n",
              " 'til',\n",
              " 'takes',\n",
              " 'pick',\n",
              " 'save',\n",
              " 'leavin',\n",
              " 'sword',\n",
              " 'di',\n",
              " 'da',\n",
              " 'grow',\n",
              " 'pride',\n",
              " 'car',\n",
              " 'funny',\n",
              " 'window',\n",
              " 'anyway',\n",
              " \"rock'n\",\n",
              " 'joy',\n",
              " 'looked',\n",
              " 'thinkin',\n",
              " 'kong',\n",
              " 'pull',\n",
              " 'per',\n",
              " 'story',\n",
              " 'cried',\n",
              " 'sunshine',\n",
              " 'catch',\n",
              " 'gettin',\n",
              " 'heartbeat',\n",
              " 'saying',\n",
              " 'singing',\n",
              " 'men',\n",
              " 'reach',\n",
              " 'somehow',\n",
              " 'trees',\n",
              " 'loving',\n",
              " 'hello',\n",
              " 'hole',\n",
              " 'school',\n",
              " 'strange',\n",
              " 'straight',\n",
              " 'insane',\n",
              " 'lips',\n",
              " 'drink',\n",
              " 'hair',\n",
              " 'kept',\n",
              " 'heat',\n",
              " 'pass',\n",
              " 'war',\n",
              " 'mercy',\n",
              " 'movin',\n",
              " 'john',\n",
              " 'mahal',\n",
              " 'radio',\n",
              " 'nt',\n",
              " 'sitting',\n",
              " 'met',\n",
              " 'minute',\n",
              " 'beautiful',\n",
              " 'dawn',\n",
              " 'passing',\n",
              " 'different',\n",
              " 'few',\n",
              " 'keeps',\n",
              " 'anything',\n",
              " 'carry',\n",
              " 'write',\n",
              " 'bound',\n",
              " 'hit',\n",
              " 'ends',\n",
              " 'shall',\n",
              " 'farm',\n",
              " 'talking',\n",
              " 'walkin',\n",
              " 'future',\n",
              " 'scene',\n",
              " 'wild',\n",
              " 'angel',\n",
              " 'send',\n",
              " 'wake',\n",
              " 'doubt',\n",
              " 'small',\n",
              " 'started',\n",
              " 'surprise',\n",
              " 'knees',\n",
              " 'earth',\n",
              " 'burn',\n",
              " 'supernatural',\n",
              " 'thee',\n",
              " 'sleigh',\n",
              " 'lang',\n",
              " 'church',\n",
              " 'stuff',\n",
              " 'caught',\n",
              " 'shadow',\n",
              " 'memory',\n",
              " 'chasing',\n",
              " 'next',\n",
              " 'forgotten',\n",
              " 'kill',\n",
              " 'loves',\n",
              " 'brought',\n",
              " 'kinda',\n",
              " 'devil',\n",
              " 'merry',\n",
              " 'faces',\n",
              " 'cinderella',\n",
              " 'precious',\n",
              " 'cotton',\n",
              " 'jeanie',\n",
              " 'verse',\n",
              " 'bridge',\n",
              " 'nowhere',\n",
              " 'drive',\n",
              " 'rush',\n",
              " 'c',\n",
              " 'special',\n",
              " 'anywhere',\n",
              " 'having',\n",
              " 'mood',\n",
              " 'breaking',\n",
              " 'laid',\n",
              " 'clouds',\n",
              " 'ocean',\n",
              " 'needed',\n",
              " 'silence',\n",
              " 'corner',\n",
              " 'sit',\n",
              " 'five',\n",
              " 'everyday',\n",
              " 'trip',\n",
              " 'golden',\n",
              " 'stronger',\n",
              " 'hangin',\n",
              " 'lovely',\n",
              " 'ng',\n",
              " 'boomerang',\n",
              " 'tired',\n",
              " 'crowd',\n",
              " 'noise',\n",
              " 'fantasy',\n",
              " 'someday',\n",
              " 'suddenly',\n",
              " 'learned',\n",
              " 'instead',\n",
              " 'desert',\n",
              " 'toys',\n",
              " 'pray',\n",
              " \"nothin'\",\n",
              " 'green',\n",
              " 'cast',\n",
              " 'paki',\n",
              " 'riverside',\n",
              " 'feels',\n",
              " 'boom',\n",
              " 'almost',\n",
              " 'dreaming',\n",
              " 'proud',\n",
              " 'flower',\n",
              " 'awake',\n",
              " 'yesterday',\n",
              " 'trouble',\n",
              " 'happened',\n",
              " 'kissed',\n",
              " 'shake',\n",
              " 'step',\n",
              " 'voulez',\n",
              " 'vous',\n",
              " 'spent',\n",
              " 'farmer',\n",
              " 'which',\n",
              " 'ay',\n",
              " 'greatest',\n",
              " 'andante',\n",
              " 'slowly',\n",
              " 'meant',\n",
              " 'sick',\n",
              " 'stood',\n",
              " 'fade',\n",
              " 'anyone',\n",
              " 'feelings',\n",
              " 'climb',\n",
              " 'guitar',\n",
              " 'closer',\n",
              " 'dying',\n",
              " 'games',\n",
              " 'phone',\n",
              " 'taken',\n",
              " 'glove',\n",
              " 'voices',\n",
              " 'doll',\n",
              " 'control',\n",
              " 'emotion',\n",
              " 'lots',\n",
              " 'dirty',\n",
              " 'news',\n",
              " 'oooh',\n",
              " 'apple',\n",
              " 'sunny',\n",
              " 'tells',\n",
              " 'horse',\n",
              " 'whenever',\n",
              " 'top',\n",
              " 'quite',\n",
              " 'poison',\n",
              " 'talkin',\n",
              " 'build',\n",
              " 'hallelujah',\n",
              " 'dancin',\n",
              " 'diamonds',\n",
              " 'liar',\n",
              " 'skin',\n",
              " 'bells',\n",
              " 'america',\n",
              " 'gonna',\n",
              " 'study',\n",
              " 'hours',\n",
              " 'kisses',\n",
              " 'return',\n",
              " 'tune',\n",
              " 'sunrise',\n",
              " 'brother',\n",
              " 'wishing',\n",
              " 'fair',\n",
              " 'treat',\n",
              " 'ending',\n",
              " 'choice',\n",
              " 'dry',\n",
              " 'wall',\n",
              " 'mighty',\n",
              " 'riding',\n",
              " 'act',\n",
              " 'cares',\n",
              " 'storm',\n",
              " 'birds',\n",
              " 'excited',\n",
              " 'rules',\n",
              " 'yellow',\n",
              " 'waterloo',\n",
              " 'ass',\n",
              " 'moo',\n",
              " 'smoke',\n",
              " 'cowboy',\n",
              " 'runnin',\n",
              " 'foolish',\n",
              " '..',\n",
              " 'boulevard',\n",
              " 'border',\n",
              " 'sabi',\n",
              " 'evening',\n",
              " 'growing',\n",
              " 'bang',\n",
              " 'moving',\n",
              " 'filled',\n",
              " 'sorrow',\n",
              " 'waitin',\n",
              " 'sittin',\n",
              " 'movie',\n",
              " 'sounds',\n",
              " 'ago',\n",
              " 'freedom',\n",
              " 'become',\n",
              " 'plans',\n",
              " 'champagne',\n",
              " 'others',\n",
              " 'ours',\n",
              " 'helen',\n",
              " 'paint',\n",
              " 'streets',\n",
              " 'tear',\n",
              " 'business',\n",
              " 'marionette',\n",
              " 'rough',\n",
              " 'hug',\n",
              " 'pa',\n",
              " 'realize',\n",
              " 'jump',\n",
              " 'jet',\n",
              " 'died',\n",
              " 'turning',\n",
              " 'hurts',\n",
              " 'decide',\n",
              " 'promise',\n",
              " 'teacher',\n",
              " 'held',\n",
              " 'breath',\n",
              " 'ticket',\n",
              " '6',\n",
              " 'race',\n",
              " 'fucking',\n",
              " 'wrote',\n",
              " 'poor',\n",
              " 'load',\n",
              " 'tryin',\n",
              " 'giddy',\n",
              " 'ikaw',\n",
              " 'longboat',\n",
              " 'mexico',\n",
              " 'damned',\n",
              " 'means',\n",
              " 'lucky',\n",
              " 'fingers',\n",
              " 'soft',\n",
              " 'crying',\n",
              " 'sailing',\n",
              " 'quiet',\n",
              " 'wings',\n",
              " 'lying',\n",
              " 'finally',\n",
              " 'half',\n",
              " 'eternity',\n",
              " 'okay',\n",
              " 'everywhere',\n",
              " 'broke',\n",
              " 'gold',\n",
              " 'single',\n",
              " 'cries',\n",
              " 'lifetime',\n",
              " \"doin'\",\n",
              " 'adore',\n",
              " 'called',\n",
              " 'band',\n",
              " 'stuck',\n",
              " 'glow',\n",
              " 'twice',\n",
              " 'bye',\n",
              " 'damn',\n",
              " 'wine',\n",
              " 'ball',\n",
              " 'secret',\n",
              " 'great',\n",
              " 'starts',\n",
              " 'worry',\n",
              " 'desire',\n",
              " 'lonesome',\n",
              " 'owe',\n",
              " 'four',\n",
              " '1',\n",
              " 'pre',\n",
              " 'asking',\n",
              " 'whiskey',\n",
              " 'heads',\n",
              " 'fever',\n",
              " 'janie',\n",
              " 'sin',\n",
              " 'fallin',\n",
              " 'rockin',\n",
              " 'runner',\n",
              " 'grace',\n",
              " 'wonderland',\n",
              " 'e',\n",
              " 'awhile',\n",
              " 'gates',\n",
              " 'tonite',\n",
              " 'pag',\n",
              " 'dixie',\n",
              " 'crawling',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSfQ0pPFyMvu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pickle.dump(data_lm.vocab.itos, open('vocab.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDkNHbow6Z9C",
        "colab_type": "code",
        "outputId": "93d0dcd1-719b-467f-bc37-357d0edb3ed5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        }
      },
      "source": [
        "learn.model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SequentialRNN(\n",
              "  (0): AWD_LSTM(\n",
              "    (encoder): Embedding(4360, 400, padding_idx=1)\n",
              "    (encoder_dp): EmbeddingDropout(\n",
              "      (emb): Embedding(4360, 400, padding_idx=1)\n",
              "    )\n",
              "    (rnns): ModuleList(\n",
              "      (0): WeightDropout(\n",
              "        (module): LSTM(400, 1152, batch_first=True)\n",
              "      )\n",
              "      (1): WeightDropout(\n",
              "        (module): LSTM(1152, 1152, batch_first=True)\n",
              "      )\n",
              "      (2): WeightDropout(\n",
              "        (module): LSTM(1152, 400, batch_first=True)\n",
              "      )\n",
              "    )\n",
              "    (input_dp): RNNDropout()\n",
              "    (hidden_dps): ModuleList(\n",
              "      (0): RNNDropout()\n",
              "      (1): RNNDropout()\n",
              "      (2): RNNDropout()\n",
              "    )\n",
              "  )\n",
              "  (1): LinearDecoder(\n",
              "    (decoder): Linear(in_features=400, out_features=4360, bias=True)\n",
              "    (output_dp): RNNDropout()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qEZK7qHyMpR",
        "colab_type": "code",
        "outputId": "ba087733-9862-41e4-b371-1edaeac13f99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "source": [
        "torch.save(learn.model, 'fine_tuned_enc_20.pth')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type SequentialRNN. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type AWD_LSTM. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type EmbeddingDropout. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ModuleList. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type WeightDropout. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LSTM. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type RNNDropout. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LinearDecoder. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yu8-NLM9yMfm",
        "colab_type": "code",
        "outputId": "6cba7b5a-85dc-4c23-8470-4ea095df764e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "source": [
        "import dill as dill\n",
        "torch.save(learn.model, 'fine_tuned_enc_20_2.pth', pickle_module=dill)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type SequentialRNN. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type AWD_LSTM. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type EmbeddingDropout. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ModuleList. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type WeightDropout. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LSTM. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type RNNDropout. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LinearDecoder. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4W7DyOx0Ook7",
        "colab_type": "code",
        "outputId": "cd84b4c2-dbbf-41c5-e38c-d9ca887d12e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        }
      },
      "source": [
        "!pip3 install torchvision"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.4.1+cu100)\n",
            "Collecting torch==1.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/05/50a05de5337f7a924bb8bd70c6936230642233e424d6a9747ef1cfbde353/torch-1.3.0-cp36-cp36m-manylinux1_x86_64.whl (773.1MB)\n",
            "\u001b[K     |████████████████████████████████| 773.1MB 21kB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.17.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.3.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n",
            "Installing collected packages: torch\n",
            "  Found existing installation: torch 0.3.0.post4\n",
            "    Uninstalling torch-0.3.0.post4:\n",
            "      Successfully uninstalled torch-0.3.0.post4\n",
            "Successfully installed torch-1.3.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHiLPT9p9bRc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from fastai import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYMtZkQa2RCX",
        "colab_type": "code",
        "outputId": "c28efaa1-1d77-4180-9d0a-492ab9e35e3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        }
      },
      "source": [
        "model = torch.load('fine_tuned_enc_20.pth')\n",
        "model.eval()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SequentialRNN(\n",
              "  (0): AWD_LSTM(\n",
              "    (encoder): Embedding(4360, 400, padding_idx=1)\n",
              "    (encoder_dp): EmbeddingDropout(\n",
              "      (emb): Embedding(4360, 400, padding_idx=1)\n",
              "    )\n",
              "    (rnns): ModuleList(\n",
              "      (0): WeightDropout(\n",
              "        (module): LSTM(400, 1152, batch_first=True)\n",
              "      )\n",
              "      (1): WeightDropout(\n",
              "        (module): LSTM(1152, 1152, batch_first=True)\n",
              "      )\n",
              "      (2): WeightDropout(\n",
              "        (module): LSTM(1152, 400, batch_first=True)\n",
              "      )\n",
              "    )\n",
              "    (input_dp): RNNDropout()\n",
              "    (hidden_dps): ModuleList(\n",
              "      (0): RNNDropout()\n",
              "      (1): RNNDropout()\n",
              "      (2): RNNDropout()\n",
              "    )\n",
              "  )\n",
              "  (1): LinearDecoder(\n",
              "    (decoder): Linear(in_features=400, out_features=4360, bias=True)\n",
              "    (output_dp): RNNDropout()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUwFUj0J4prs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "infile = open('vocab.pkl', 'rb')\n",
        "data_lm = pickle.load(infile)\n",
        "infile.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEhulTZB4poo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgXKLviK4pl3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0Qi7XTg2Q-H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT = \"we are learning transfer learning\"\n",
        "N_WORDS = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGe2Dwg_2Q6z",
        "colab_type": "code",
        "outputId": "6c39523b-e930-4d41-e524-803768a66141",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "poem = model.predict(TEXT, N_WORDS, temperature = 0.75)\n",
        "print(poem)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-38afc09fc60b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpoem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_WORDS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    583\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 585\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'SequentialRNN' object has no attribute 'predict'"
          ]
        }
      ]
    }
  ]
}